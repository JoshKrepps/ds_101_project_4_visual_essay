{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0c34bd3",
   "metadata": {},
   "source": [
    "# Project 4: Emotions of JMU\n",
    "## Understanding the Place where we Study\n",
    "### [Josh]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87993139",
   "metadata": {},
   "source": [
    "## üìö Table of Contents\n",
    "\n",
    "### üìã Getting Started\n",
    "- [Instructions](#instructions)\n",
    "- [Part 1: Research Overview](#part-1-research-overview)\n",
    "  - [1.1 Corpus Description](#11-corpus-description)\n",
    "  - [1.2 Hypothesis](#12-hypothesis)\n",
    "\n",
    "### üîç Data Exploration  \n",
    "- [Part 2: Exploratory Data Analysis](#part-2-exploratory-data-analysis)\n",
    "  - [2.1 Visualization 1](#21-visualization-1-change-title-depending-on-visualization)\n",
    "  - [2.2 Visualization 2](#22-visualization-2-change-title-depending-on-visualization)\n",
    "\n",
    "### üßπ Data Processing\n",
    "- [Part 3: Data Cleaning and Refinement](#part-3-data-cleaning-and-refinement)\n",
    "  - [3.1 Toponym Misalignment Analysis](#31-toponym-misalignment-analysis)\n",
    "  - [3.2 Toponym Refinement](#32-toponym-refinement)\n",
    "  - [3.3 Revised Map](#33-revised-map)\n",
    "  - [3.4 Map Customization](#34-map-customization)\n",
    "\n",
    "### üó∫Ô∏è Spatial Analysis\n",
    "- [Part 4: Spatial Comparison](#part-4-spatial-comparison)\n",
    "  - [4.1 JMU Spatial Distribution](#41-jmu-spatial-distribution)\n",
    "  - [4.2 Spatial Analysis](#42-spatial-analysis)\n",
    "\n",
    "### üòä Sentiment Analysis\n",
    "- [Part 5: Sentiment Analysis Comparison](#part-5-sentiment-analysis-comparison)\n",
    "\n",
    "### ‚è∞ Time Series Analysis\n",
    "- [Part 6: Time Series Animation Analysis](#part-6-time-series-animation-analysis)\n",
    "\n",
    "### üìù Final Report\n",
    "- [Part 7: Conclusion and Future Research](#part-7-conclusion-and-future-research)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97da1026",
   "metadata": {},
   "source": [
    "<style>\n",
    "/* Hide all code cells for clean essay presentation */\n",
    ".jp-CodeCell .jp-InputArea {\n",
    "    display: none !important;\n",
    "}\n",
    "\n",
    "/* For VS Code notebook rendering */\n",
    ".cell[data-cell-type=\"code\"] .input-container {\n",
    "    display: none !important;\n",
    "}\n",
    "\n",
    "/* Alternative selectors for different notebook environments */\n",
    "div.code_cell div.input_area {\n",
    "    display: none !important;\n",
    "}\n",
    "\n",
    ".CodeMirror,\n",
    ".highlight {\n",
    "    display: none !important;\n",
    "}\n",
    "\n",
    "/* Center and resize the entire notebook content */\n",
    ".jp-Notebook {\n",
    "    width: 80% !important;\n",
    "    max-width: 1200px !important;\n",
    "    margin: 0 auto !important;\n",
    "}\n",
    "\n",
    "/* For VS Code notebook rendering */\n",
    ".notebook-container {\n",
    "    width: 80% !important;\n",
    "    max-width: 1200px !important;\n",
    "    margin: 0 auto !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa95fa",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e3f2fd; border: 2px solid #1976d2; border-radius: 10px; padding: 20px; margin: 10px 0;\">\n",
    "\n",
    "### üìã Assignment Overview\n",
    "\n",
    "We have spent the last several weeks trying to reproduce the work of Ryan Heuser in [\"The Emotions of London\"](https://litlab.stanford.edu/LiteraryLabPamphlet13.pdf). Rather than London, we have scraped JMU's Reddit feed to establish the emotions of JMU by first geoparsing the data for locations, cleaning those locations, and then attaching emotions to them. Our ultimate goal was to get a better sense of how JMU students think of the place where they live and study. In particular, we are interested in what the world looks like from the perspective of a JMU students who post to Reddit. Using our data we can start to answer such questions as: \n",
    "\n",
    " - What places are often talked about? \n",
    " - How are they talked about? \n",
    " - What might this tell us about how JMU works as an imagined community?\n",
    "\n",
    "In this visual essay, you are going create a fuller picture of the world as perceived through JMU students by contrasting it with another school in Virginia. Undoubtedly, dorms, food, parking are the concerns of every college students, but in looking at contrasting data sets we can try to figure out what makes the JMU community unique compared to other schools.\n",
    "\n",
    "### üìù Instructions\n",
    "\n",
    "The following is a self-contained visual essay. Your task is to complete it as a group. \n",
    "\n",
    "Each section has its own set of instructions and tasks that fall into the following categories: \n",
    "\n",
    "- **üìä Action Items** = Data exploration and technical tasks\n",
    "- **‚úçÔ∏è Writing Tasks** = Analysis and interpretation assignments  \n",
    "- **üîß Technical Steps** = Code implementation instructions\n",
    "- **üí° Examples** = Sample content and guidance\n",
    "- **‚ö†Ô∏è Important** = Critical requirements and warnings\n",
    "\n",
    "Each part of the essay draws on a previous skill we have learned, and while you can give ownership of each part to a different team member, it is best to walk through the entire essay with your team twice. First, at the beginning to get a sense of the data and your potential hypothesis, and second, as a final run through to make sure all the parts are coherent. Once you have completed all the sections, delete all of the instructions and leave only your writing, the code, and the visualizations.\n",
    "\n",
    "### ‚è∞ Timeline\n",
    "\n",
    "**Final Essay is Due Tuesday Nov 11th**\n",
    "\n",
    "1. **Nov. 3rd** - Assignment Introduction - Complete Parts 1-2\n",
    "   - *Homework* - Complete Parts 3-4\n",
    "2. **Nov. 5th** - In class work day - Convene about 3-4, move on to 5 and 6\n",
    "3. **Nov. 10** - Discuss Krygier and Wood Reading - Final Crunch Last 30 Minutes\n",
    "4. **Nov. 12** - Final Project Introduction: Deep Mapping Harrisonburg\n",
    "\n",
    "### üéØ End Product\n",
    "\n",
    "A sample version of the essay with the instructions still included can be viewed here: [project_4_visual_essay](https://joostburgers.github.io/ds_101_project_4_visual_essay/)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd63213d",
   "metadata": {},
   "source": [
    "<div style=\"border-top: 2px solid #64b5f6; margin-top: 30px; padding-top: 20px;\">\n",
    "\n",
    "## Part 1: Research Overview\n",
    "### Introduction\n",
    "\n",
    "Your introduction should include:\n",
    "- Brief overview of the two corpora you are studying (i.e. JMU and UNC)\n",
    "- Your hypothesis about these corpora\n",
    "- Your findings based on \n",
    "  - Exploratory Data Analysis (Voyant)\n",
    "  - Your major finding using spatial analysis\n",
    "  - Your major finding using sentiment maps\n",
    "- Overall conclusion\n",
    "  \n",
    "Each element should be about a sentence or two\n",
    "The introduction should be written last\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dab9573",
   "metadata": {},
   "source": [
    "### 1.1 Corpus Description\n",
    "\n",
    "#### üìä Action Items\n",
    "\n",
    "**üìã Data Exploration**\n",
    "- Open and inspect: `assets\\data\\jmu_reddit_geoparsed_clean.csv`\n",
    "- Your own institution data set: `group_data_packets\\group_NUMBER\\python\\INSTITUTION_processed.csv`\n",
    "  - For example: `group_data_packets\\group_6\\python\\UNC_processed.csv`\n",
    "\n",
    "#### ‚úçÔ∏è Writing Task\n",
    "\n",
    "Skim through the records and try to get a sense of what the data is about. Come up with a working theory as to what might be an important point of comparison between your institution and JMU.\n",
    "\n",
    "**Write** one paragraph in which you compare or contrast each corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f4c09d",
   "metadata": {},
   "source": [
    "### 1.2 Hypothesis\n",
    "\n",
    "#### ‚úçÔ∏è Writing Task\n",
    "\n",
    "Formulate a working theory of how the two corpora differ or compare and explain how you might see that reflected in the data. \n",
    "\n",
    "**‚ö†Ô∏è Important Requirements:**\n",
    "- The hypothesis **must** be related to space and sentiment\n",
    "- Example of what **NOT** to do: \"JMU students love math classes more than UNC students\" (not spatial and cannot be answered by our data)\n",
    "\n",
    "#### üí° Sample Hypotheses\n",
    "\n",
    "**Regional Scale Examples:**\n",
    "1. UNC attracts more students from the southeast than JMU and therefore more positive sentiments will appear across South Carolina, Georgia, Alabama, and Florida.\n",
    "\n",
    "**Local Scale Examples:**\n",
    "\n",
    "2. JMU has a very positive college atmosphere, and therefore sentiment around campus will appear more positive than that of UNC.\n",
    "\n",
    "Note that these hypotheses operate at two different spatial scales: regional and local."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa87e41",
   "metadata": {},
   "source": [
    "<div style=\"border-top: 2px solid #64b5f6; margin-top: 30px; padding-top: 20px;\">\n",
    "\n",
    "## Part 2: Exploratory Data Analysis\n",
    "\n",
    "#### üìä Action Items\n",
    "\n",
    "**üìã Data Preparation**\n",
    "- Use the zip file in your group directory (`group_data_packets/voyant/INSTITUTION_JMU.zip`) to run Voyant analysis at https://www.voyant-tools.org\n",
    "\n",
    "#### ‚úçÔ∏è Writing Task\n",
    "\n",
    "Write a brief overview of the type of evidence you are hoping to find with your Voyant analysis.\n",
    "\n",
    "**üí° Example:** \"We will compare the difference in 'school spirit' between UNC and JMU by looking at terms related to sports, social events, and mascots in the trends tool and the context tool.\"\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f437a1",
   "metadata": {},
   "source": [
    "### 2.1 Visualization 1 [Change Title Depending on Visualization]\n",
    "\n",
    "#### ‚úçÔ∏è Writing Task\n",
    "Explain what this visualization does and how it might help your research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09664cb3",
   "metadata": {},
   "source": [
    "#### üìä Add Visualization 1 Here\n",
    "\n",
    "**üîß Technical Steps:**\n",
    "\n",
    "1. Create the visualization you want in Voyant Tools\n",
    "2. Click on the **export button** at the top right of the visualization\n",
    "3. Open `Export View (Tools and Data)` dropdown\n",
    "4. Select `an HTML snippet for embedding this view in another web page` radio button\n",
    "5. Copy the snippet that starts with `<iframe>` and ends with the closing tag `</iframe>`\n",
    "6. Replace the whole string in the markdown cell below\n",
    "\n",
    "**üì∫ Video Tutorial:** https://youtu.be/FFHaNLVLmz4?si=MJxohF7vd2PRx9Ox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb91d713",
   "metadata": {},
   "source": [
    "\n",
    "<iframe style='width: 637px; height: 478px;' src='https://voyant-tools.org/tool/Trends/?query=mr&query=mrs&query=said&query=miss&query=think&corpus=austen'></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b822789",
   "metadata": {},
   "source": [
    "#### ‚úçÔ∏è Visualization Analysis\n",
    "\n",
    "**Write** how the visualization confirms or complicates your hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ff452",
   "metadata": {},
   "source": [
    "### 2.2 Visualization 2 [Change Title Depending on Visualization]\n",
    "\n",
    "#### ‚úçÔ∏è Writing Task\n",
    "Explain what this visualization does and how it might help your research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fd7a2f",
   "metadata": {},
   "source": [
    "\n",
    "<iframe style='width: 637px; height: 497px;' src='https://voyant-tools.org/tool/Cirrus/?corpus=austen'></iframe>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dbbc15",
   "metadata": {},
   "source": [
    "#### Visualization Analysis\n",
    "\n",
    "‚úçÔ∏è **Write** how the visualization confirms or complicates your hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b25d3",
   "metadata": {},
   "source": [
    "<div style=\"border-top: 2px solid #64b5f6; margin-top: 30px; padding-top: 20px;\">\n",
    "\n",
    "## Part 3: Data Cleaning and Refinement\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a598013",
   "metadata": {},
   "source": [
    "#### üìã About `_processed.csv` Files\n",
    "\n",
    "Each group has been provided with a `_processed.csv` file. This file includes all of the necessary data to create sentiment maps. The issue is that this is still spatial data in its raw form and contains erroneous data. In this section, you will take your `_processed.csv` file and clean it up. \n",
    "\n",
    "For the sake of example, a UNC dataset has been preloaded to show what the result should look like.\n",
    "\n",
    "**‚ö†Ô∏è Note:** Delete this cell before turning in the final version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38fc4bee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m     importlib.reload(sys.modules[\u001b[33m'\u001b[39m\u001b[33mdata_cleaning_utils\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Core data analysis library - like Excel but for Python\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Import our custom functions for cleaning and analyzing location data\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata_cleaning_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     clean_institution_dataframe,      \u001b[38;5;66;03m# Standardizes and cleans location data\u001b[39;00m\n\u001b[32m     19\u001b[39m     get_data_type_summary,            \u001b[38;5;66;03m# Shows what types of data we have\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     create_time_animation_data,       \u001b[38;5;66;03m# Prepares data for animated time series\u001b[39;00m\n\u001b[32m     24\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SETUP: Import Libraries and Load Data\n",
    "# =============================================================================\n",
    "# This cell sets up all the tools we need for spatial sentiment analysis\n",
    "\n",
    "# Force reload to pick up any changes to data_cleaning_utils\n",
    "# This ensures we get the latest version of our custom functions\n",
    "import importlib\n",
    "import sys\n",
    "if 'data_cleaning_utils' in sys.modules:\n",
    "    importlib.reload(sys.modules['data_cleaning_utils'])\n",
    "\n",
    "# Core data analysis library - like Excel but for Python\n",
    "import pandas as pd\n",
    "\n",
    "# Import our custom functions for cleaning and analyzing location data\n",
    "from data_cleaning_utils import (\n",
    "    clean_institution_dataframe,      # Standardizes and cleans location data\n",
    "    get_data_type_summary,            # Shows what types of data we have\n",
    "    get_null_value_summary,           # Identifies missing data\n",
    "    create_location_counts,           # Counts how often places are mentioned\n",
    "    create_location_sentiment,        # Calculates average emotions by location\n",
    "    create_time_animation_data,       # Prepares data for animated time series\n",
    ")\n",
    "\n",
    "# Interactive plotting library - creates maps and charts\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.offline as pyo\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURE PLOTLY FOR HTML EXPORT\n",
    "# =============================================================================\n",
    "# Configure Plotly for optimal HTML export compatibility\n",
    "\n",
    "# Method 1: Set renderer for HTML export (use 'notebook' for Jupyter environments)\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "# Method 2: Configure Plotly for offline use (embeds JavaScript in HTML)\n",
    "pyo.init_notebook_mode(connected=False)  # False = fully offline, no external dependencies\n",
    "\n",
    "# Method 3: Set template for clean HTML appearance\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "# Method 4: Configure Plotly to include plotly.js in HTML exports\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=False)\n",
    "\n",
    "\n",
    "\n",
    "# Load the cleaned JMU Reddit data (already processed and ready to use)\n",
    "# This contains: posts, locations, coordinates, sentiment scores, and dates\n",
    "df_jmu = pd.read_pickle(\"assets/data/jmu_reddit_geoparsed_clean.pickle\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD YOUR INSTITUTION'S DATA\n",
    "# =============================================================================\n",
    "# Replace the group number and institution name with your assigned data\n",
    "\n",
    "# üìù TO DO: Update these paths for your group\n",
    "# Replace \"group_6\" with your group number (e.g., \"group_1\", \"group_2\", etc.)\n",
    "# Replace \"UNC_processed.csv\" with your institution's file name\n",
    "df_institution = pd.read_csv(\"group_data_packets/group_6/python/UNC_processed.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d9d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE RAW LOCATION MAP (Before Cleaning)\n",
    "# =============================================================================\n",
    "# This shows the \"messy\" data before we fix location errors\n",
    "# You'll see why data cleaning is essential!\n",
    "\n",
    "# STEP 1: Count how many times each place is mentioned\n",
    "# Group identical place names together and count occurrences\n",
    "place_counts = df_institution.groupby('place').agg({\n",
    "    'place': 'count',           # Count how many times each place appears\n",
    "    'latitude': 'first',        # Take the first latitude coordinate for each place\n",
    "    'longitude': 'first',       # Take the first longitude coordinate for each place\n",
    "    'place_type': 'first'       # Take the first place type classification\n",
    "}).rename(columns={'place': 'count'})  # Rename the count column for clarity\n",
    "\n",
    "# STEP 2: Prepare data for mapping\n",
    "# Reset index makes 'place' a regular column instead of an index\n",
    "place_counts = place_counts.reset_index()\n",
    "\n",
    "# Remove any places that don't have valid coordinates (latitude/longitude)\n",
    "# This prevents errors when trying to plot points on the map\n",
    "place_counts = place_counts.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# STEP 3: Create interactive scatter map\n",
    "# Each dot represents a place, size = how often it's mentioned\n",
    "fig = px.scatter_map(\n",
    "    place_counts,                    # Our prepared data\n",
    "    lat='latitude',                  # Y-coordinate (north-south position)\n",
    "    lon='longitude',                 # X-coordinate (east-west position)\n",
    "    size='count',                    # Bigger dots = more mentions\n",
    "    hover_name='place',              # Show place name when hovering\n",
    "    hover_data={                     # Additional info in hover tooltip\n",
    "        'count': True,               # Show mention count\n",
    "        'place_type': True,          # Show what type of place it is\n",
    "        'latitude': ':.4f',          # Show coordinates with 4 decimal places\n",
    "        'longitude': ':.4f'\n",
    "    },\n",
    "    size_max=25,                     # Maximum dot size on map\n",
    "    zoom=4,                          # How zoomed in the map starts (higher = closer)\n",
    "    title='Raw Location Data: Places Mentioned in UNC Reddit Posts',\n",
    "    center=dict(lat=35.5, lon=-80)   # Center map on North Carolina for UNC\n",
    ")\n",
    "\n",
    "# STEP 4: Customize map appearance\n",
    "fig.update_layout(\n",
    "    map_style=\"carto-positron\",      # Clean, light map style\n",
    "    width=800,                       # Map width in pixels\n",
    "    height=600,                      # Map height in pixels\n",
    "    title_font_size=16,              # Title text size\n",
    "    title_x=0.5                      # Center the title\n",
    ")\n",
    "\n",
    "\n",
    "# Configure for HTML export compatibility\n",
    "fig.show(config={'displayModeBar': True, 'displaylogo': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b926fa6",
   "metadata": {},
   "source": [
    "### 3.1 Toponym Misalignment Analysis\n",
    "\n",
    "#### üìä Action Items\n",
    "Study the map of your institution alongside the .csv file. Try to determine some of the major mistakes the geoparser has made. \n",
    "\n",
    "**üí° Example:** In the map above, `Carolina` is placed on the North Carolina and South Carolina border. In all likelihood, Reddit posters mean `North Carolina` when they post `Carolina`.\n",
    "\n",
    "#### ‚úçÔ∏è Writing Task\n",
    "\n",
    "Write a description of the major toponym misalignments in your dataset.\n",
    "\n",
    "**üí° Sample Description:**\n",
    "\"The University of North Carolina's home campus is in Chapel Hill, NC and most locations should appear around those coordinates. There are some major erroneous locations, however. In the main, Chapel Hill has been placed in Tennessee, and likewise there is a Hill Chapel in Virginia, but this likely refers to Chapel Hill in NC as well.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20d14b2",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fdf6e3ff; border: 2px solid #fad3abff; border-radius: 10px; padding: 20px; margin: 10px 0;\">\n",
    "\n",
    "### 3.2 Toponym Refinement\n",
    "\n",
    "In this section you are going to clean up the map above by fixing some of the major locations and getting a sense of the data.\n",
    "\n",
    "**üì∫ Complete Video Tutorial:** https://www.youtube.com/watch?v=TZgRYn1TxGI\n",
    "\n",
    "#### üîß Step 1: Access Your Data\n",
    "1. Navigate to your group in `group_data_packets`\n",
    "2. Go to the `python` folder\n",
    "3. Open the CSV file that ends with `_processed.csv` (e.g., `GMU_processed.csv`)\n",
    "\n",
    "#### üìã Step 2: Data Structure\n",
    "Your CSV file should contain the following **14 columns:**\n",
    "- **school_name** - Institution identifier\n",
    "- **unique_id** - Record identifier  \n",
    "- **date** - Post date\n",
    "- **sentences** - Text content\n",
    "- **roberta_compound** - Sentiment score\n",
    "- **place** - Original location name\n",
    "- **latitude** - Original coordinates\n",
    "- **longitude** - Original coordinates\n",
    "- **revised_place** *(empty)* - Corrected location name\n",
    "- **revised_latitude** *(empty)* - Corrected latitude\n",
    "- **revised_longitude** *(empty)* - Corrected longitude\n",
    "- **place_type** *(empty)* - Location category\n",
    "- **false_positive** *(empty)* - Invalid location flag\n",
    "- **checked_by** *(empty)* - Quality control tracker\n",
    "\n",
    "#### üîß Step 3: Data Cleaning Process\n",
    "\n",
    "**üìä Open in Google Sheets:** Upload your CSV file to Google Sheets for collaborative editing\n",
    "\n",
    "**üîß Fix Locations:** Enter corrected data in the `revised_` columns for mistaken locations\n",
    "\n",
    "**üè∑Ô∏è Categorize Places:** Use the `place_type` column with these standardized categories:\n",
    "   - **Country** - National boundaries\n",
    "   - **State** - State/province level\n",
    "   - **County** - County/region level\n",
    "   - **City** - Municipal areas\n",
    "   - **Neighborhood** - Local districts\n",
    "   - **University** - Educational institutions\n",
    "   - **Building** - Specific structures\n",
    "   - **Road** - Streets and highways\n",
    "\n",
    "   **üí° Pro Tip:** Create a data validation dropdown in Google Sheets for consistent place types\n",
    "\n",
    "**‚ùå Mark False Positives:** Set `false_positive` to `True` for sentences that don't actually reference locations\n",
    "\n",
    "**üë• Track Progress:** Enter your name in `checked_by` to coordinate team efforts\n",
    "\n",
    "#### üíæ Step 4: Export Clean Data\n",
    "1. Go to **File ‚Üí Download ‚Üí Comma Separated Values (.csv)**\n",
    "2. Save as: `[institution]_processed_clean.csv` in the same folder\n",
    "   - **Example:** `group_2/python/ODU_processed_clean.csv`\n",
    "\n",
    "**‚ö†Ô∏è Note:** Delete this cell before turning in the final version.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2990e495",
   "metadata": {},
   "source": [
    "### 3.3 Revised Map\n",
    "\n",
    "#### ‚úçÔ∏è Writing Task\n",
    "\n",
    "Explain the major fixes you made to the map and what you learned about the dataset in the process. You can answer any of the following questions:\n",
    " - What were some places of note on the campus you investigated? \n",
    " - What appeared to be the main concern many of the posts?\n",
    " - What were some places that surprised you?\n",
    "\n",
    "#### üîß Technical Implementation\n",
    "\n",
    "**Code Changes Required:**\n",
    "1. Run the python below to display map. Remember, this will only work if the .csv file was saved properly.\n",
    "2. You will have to change the code to properly set it to your group and file.\n",
    "  \n",
    "  ```python\n",
    "  df_institution_cleaned = pd.read_csv('group_data_packets/group_6/python/UNC_processed_clean.csv')\n",
    "  ```\n",
    "  \n",
    "**‚ö†Ô∏è Remember:** You are changing the group number and the institution name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12bda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD CLEANED DATA\n",
    "# =============================================================================\n",
    "# Load the CSV file you manually cleaned in Google Sheets\n",
    "\n",
    "# üìù TO DO: Update these paths for your group\n",
    "# Replace \"group_6\" with your group number\n",
    "# Replace \"UNC_processed_clean.csv\" with your institution's cleaned file\n",
    "df_institution_cleaned = pd.read_csv(\n",
    "    \"group_data_packets/group_6/python/UNC_processed_clean.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36354f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# APPLY DATA CLEANING FUNCTIONS\n",
    "# =============================================================================\n",
    "# Use our custom function to standardize the cleaned data\n",
    "\n",
    "# Apply the cleaning function to standardize data types and handle missing values\n",
    "# This function ensures all datasets have the same format for consistent analysis\n",
    "\n",
    "df_institution_cleaned = clean_institution_dataframe(df_institution_cleaned)\n",
    "\n",
    "# Display first few rows to verify the cleaning worked properly\n",
    "# This shows the structure and sample content of your cleaned data\n",
    "df_institution_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7e7a0a",
   "metadata": {},
   "source": [
    "### 3.4 Map Customization\n",
    "\n",
    "#### üîß Map Adjustment Instructions\n",
    "- The revised map will display below. \n",
    "- Tweak the visuals on the map by setting the zoom and the center.\n",
    "  - Find the snippet below in the `px.scatter_map` function\n",
    "  - Change the `zoom`, `lat`, and `long` to set your view.\n",
    "\n",
    "```python\n",
    "zoom=2, # Set the zoom level here\n",
    "center=dict(lat=38.5, lon=-106),  # Set the center of your view here\n",
    "```\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb99f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CREATE CLEANED LOCATION MAP (After Manual Corrections)\n",
    "# =============================================================================\n",
    "# This map shows your data AFTER you fixed the location errors\n",
    "# Compare this to the raw map above to see the improvement!\n",
    "\n",
    "# STEP 1: Count occurrences using CLEANED/CORRECTED location data\n",
    "# Now we use 'revised_place' instead of 'place' - these are your corrections!\n",
    "place_counts = (\n",
    "    df_institution_cleaned.groupby(\"revised_place\")  # Group by corrected place names\n",
    "    .agg(\n",
    "        {\n",
    "            \"revised_place\": \"count\",        # Count mentions of each corrected place\n",
    "            \"revised_latitude\": \"first\",     # Use corrected latitude coordinates\n",
    "            \"revised_longitude\": \"first\",    # Use corrected longitude coordinates\n",
    "            \"place_type\": \"first\",           # Keep place type classification\n",
    "        }\n",
    "    )\n",
    "    .rename(columns={\"revised_place\": \"count\"})  # Rename count column for clarity\n",
    ")\n",
    "\n",
    "# STEP 2: Prepare data for mapping\n",
    "place_counts = place_counts.reset_index()  # Make 'revised_place' a regular column\n",
    "\n",
    "# Remove places without valid corrected coordinates\n",
    "place_counts = place_counts.dropna(subset=[\"revised_latitude\", \"revised_longitude\"])\n",
    "\n",
    "# STEP 3: Create the cleaned location map\n",
    "fig = px.scatter_map(\n",
    "    place_counts,\n",
    "    lat=\"revised_latitude\",          # Use corrected Y-coordinates\n",
    "    lon=\"revised_longitude\",         # Use corrected X-coordinates\n",
    "    size=\"count\",                    # Dot size = mention frequency\n",
    "    hover_name=\"revised_place\",      # Show corrected place name on hover\n",
    "    hover_data={\n",
    "        \"count\": True,               # Show how many mentions\n",
    "        \"place_type\": True,          # Show place category\n",
    "        \"revised_latitude\": \":.4f\",   # Show corrected coordinates\n",
    "        \"revised_longitude\": \":.4f\",\n",
    "    },\n",
    "    size_max=25,                     # Maximum dot size\n",
    "    title=\"Cleaned Location Data: Places Mentioned in UNC Reddit Posts\",\n",
    "    zoom=2,                          # üìù TO DO: Adjust zoom level for your region\n",
    "    center=dict(lat=38.5, lon=-106), # üìù TO DO: Adjust center coordinates\n",
    ")\n",
    "\n",
    "# STEP 4: Customize map appearance\n",
    "fig.update_layout(\n",
    "    map_style=\"carto-positron\",      # Clean, readable map style\n",
    "    width=800, \n",
    "    height=600, \n",
    "    title_font_size=16, \n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "\n",
    "# Display with HTML export configuration\n",
    "fig.show(config={'displayModeBar': True, 'displaylogo': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b76b75",
   "metadata": {},
   "source": [
    "#### Revision Insights\n",
    "‚úçÔ∏è \n",
    "**Write** any new spatial insights you arrived at now that you have fixed the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d3d5b",
   "metadata": {},
   "source": [
    "<div style=\"border-top: 2px solid #64b5f6; margin-top: 30px; padding-top: 20px;\">\n",
    "\n",
    "## Part 4: Spatial Comparison\n",
    "\n",
    "In this section you are going to compare the spatial distribution of JMU and your institution. You will create two maps using the custom `create_locations_counts()` function. \n",
    "\n",
    "#### üîß Function Parameters\n",
    "\n",
    "This function has two key parameters:\n",
    "\n",
    " - **`minimum_count=`** - Sets the minimum number of times a location has to appear before it appears on the map. Setting this to the default `2` means that if a location appears once it will not register\n",
    " - **`place_type_filter=`** - This uses the `place_type` column to filter out only the types of places you want. The default is `None`, but adding a list of places i.e. (`place_type_filter=[\"University\", \"Building\"]`) only shows those places. In the sample below, only \"States\", \"City\", and \"Country\" places will show up. \n",
    " \n",
    "**‚ö†Ô∏è NOTE:** This does mean you would have had to tag place types properly in the cleanup process\n",
    "\n",
    "#### üí° Example Usage\n",
    "```python\n",
    "create_location_counts(\n",
    "    df_institution_cleaned, \n",
    "    minimum_count=2, \n",
    "    place_type_filter=[\"State\", \"City\", \"Country\"]\n",
    ")\n",
    "```\n",
    "\n",
    "#### üîß Customization Instructions\n",
    "\n",
    "**‚ö†Ô∏è Important:** Make sure that `minimum_count` and `place_type_filter` for `create_locations_counts` are the same for both maps.\n",
    "\n",
    "**Visual Customization:**\n",
    "- Tweak the center and zoom of your map to highlight an important contrast\n",
    "- Set the `color_discrete_sequence=px.colors.qualitative.Plotly` to something of your choice\n",
    "  - **Color Reference:** https://plotly.com/python/discrete-color/#color-sequences-in-plotly-express\n",
    "\n",
    "**‚ö†Ô∏è Note:** Delete this cell for the final version\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28661530",
   "metadata": {},
   "source": [
    "### 4.1 JMU Spatial Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5baeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# JMU SPATIAL DISTRIBUTION MAP\n",
    "# =============================================================================\n",
    "# Create a filtered map showing only certain types of places for JMU\n",
    "\n",
    "# STEP 1: Use custom function to filter and count JMU locations\n",
    "# This function applies the same filtering to both datasets for fair comparison\n",
    "JMU_filtered_locations = create_location_counts(\n",
    "    df_jmu,                          # JMU Reddit data\n",
    "    minimum_count=2,                 # Only show places mentioned 2+ times\n",
    "    place_type_filter=['State', 'City', 'Country']  # Only these place types\n",
    ")\n",
    "\n",
    "\n",
    "# STEP 2: Create colored scatter map\n",
    "# Each place type gets a different color to show spatial patterns\n",
    "fig = px.scatter_map(\n",
    "    JMU_filtered_locations,\n",
    "    lat=\"revised_latitude\",\n",
    "    lon=\"revised_longitude\", \n",
    "    size=\"count\",                    # Dot size = mention frequency\n",
    "    color=\"place_type\",              # Different colors for different place types\n",
    "    hover_name=\"revised_place\",\n",
    "    hover_data={\n",
    "        \"count\": True,\n",
    "        \"place_type\": True,\n",
    "        \"revised_latitude\": \":.4f\",\n",
    "        \"revised_longitude\": \":.4f\",\n",
    "    },\n",
    "    size_max=25,\n",
    "    zoom=2,                          # üìù TO DO: Adjust to highlight interesting patterns\n",
    "    title=\"Cleaned Location Data: Places Mentioned in JMU Reddit Posts\",\n",
    "    center=dict(lat=38.5, lon=-106), # üìù TO DO: Center on area of interest\n",
    "    color_discrete_sequence=px.colors.qualitative.Plotly  # Categorical color palette\n",
    ")\n",
    "\n",
    "# STEP 3: Customize layout\n",
    "fig.update_layout(\n",
    "    map_style=\"carto-positron\", \n",
    "    width=800, \n",
    "    height=600, \n",
    "    title_font_size=16, \n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "\n",
    "# Display with HTML export configuration\n",
    "fig.show(config={'displayModeBar': True, 'displaylogo': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943c205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# YOUR INSTITUTION'S SPATIAL DISTRIBUTION MAP\n",
    "# =============================================================================\n",
    "# Create a comparable map for your institution using identical filtering\n",
    "\n",
    "# STEP 1: Apply the same filtering to your institution's data\n",
    "# Using identical parameters ensures fair comparison with JMU\n",
    "institution_filtered_locations = create_location_counts(\n",
    "    df_institution_cleaned,          # Your cleaned institution data\n",
    "    minimum_count=2,                 # Same minimum as JMU map\n",
    "    place_type_filter=[\"State\", \"City\", \"Country\"]  # Same place types as JMU\n",
    ")\n",
    "\n",
    "\n",
    "# STEP 2: Create matching visualization\n",
    "# Keep all settings the same as JMU map for direct comparison\n",
    "fig_institution_cleaned = px.scatter_map(\n",
    "    institution_filtered_locations,\n",
    "    lat=\"revised_latitude\",\n",
    "    lon=\"revised_longitude\",\n",
    "    size=\"count\",\n",
    "    color=\"place_type\",              # Same color coding as JMU map\n",
    "    hover_name=\"revised_place\",\n",
    "    hover_data={\n",
    "        \"count\": True,\n",
    "        \"place_type\": True,\n",
    "        \"revised_latitude\": \":.4f\",\n",
    "        \"revised_longitude\": \":.4f\",\n",
    "    },\n",
    "    size_max=25,                     # Same size scale as JMU\n",
    "    zoom=2,                          # üìù TO DO: Adjust for your region\n",
    "    title=\"Cleaned Location Data: Places Mentioned in UNC Reddit Posts\",  # üìù TO DO: Update institution name\n",
    "    center=dict(lat=38.5, lon=-106), # üìù TO DO: Center on your region\n",
    "    color_discrete_sequence=px.colors.qualitative.Plotly,  # Same colors as JMU\n",
    ")\n",
    "\n",
    "# STEP 3: Apply identical layout settings\n",
    "fig_institution_cleaned.update_layout(\n",
    "    map_style=\"carto-positron\",      # Same style as JMU map\n",
    "    width=800, \n",
    "    height=600, \n",
    "    title_font_size=16, \n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Display with HTML export configuration\n",
    "fig_institution_cleaned.show(config={'displayModeBar': True, 'displaylogo': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae8a78",
   "metadata": {},
   "source": [
    "### 4.2 Spatial Analysis\n",
    "\n",
    "#### ‚úçÔ∏è Writing Task\n",
    "\n",
    "Write a paragraph on an important spatial difference or similarity between the two datasets that confirms or complicates your hypothesis.\n",
    "\n",
    "**üí° Example:** \"While we theorized that UNC would have a significant number of posts about the Southeast, the mapping data does not reveal this. Instead, the Reddit feed rarely speaks about states outside of North Carolina, and when it does it is about institutions out west.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166283fc",
   "metadata": {},
   "source": [
    "<div style=\"border-top: 2px solid #64b5f6; margin-top: 30px; padding-top: 20px;\">\n",
    "\n",
    "## Part 5: Sentiment Analysis Comparison\n",
    "\n",
    "In this section, you are going to compare the sentiments by location for each institution. You are going to do so by first customizing the `create_location_sentiment()` function. \n",
    "\n",
    "#### üîß Function Parameters\n",
    "\n",
    "This takes the same parameters as the `create_location_counts()` function above:\n",
    "\n",
    "- **`minimum_count=`** - Sets the minimum number of times a location has to appear before it appears on the map. Setting this to the default `2` means that if a location appears once it will not register\n",
    " - **`place_type_filter=`** - This uses the `place_type` column to filter out only the types of places you want. The default is `None`, but adding a list of places i.e. (`place_type_filter=[\"University\", \"Building\"]`) only shows those places. \n",
    "   - **üí° Tip:** You might consider showing only one type of place if it helps make your argument. For example, if you are investigating school spirit, it makes the most sense to look at Universities and buildings.\n",
    " - **‚ö†Ô∏è NOTE:** `place_type_filter` only works if you tagged places properly in the cleanup process. \n",
    "\n",
    "#### üí° Example Usage\n",
    "```python\n",
    "create_location_sentiment(\n",
    "    df_jmu,\n",
    "    minimum_count=2,\n",
    "    place_type_filter=None  # Include all place types\n",
    ")\n",
    "```\n",
    "\n",
    "#### üîß Customization Instructions\n",
    "\n",
    "**Visual Optimization:**\n",
    "- Tweak the center and zoom of your map to highlight an important contrast\n",
    "- Experiment with different divergent color scales to optimize the visuals\n",
    "  - **Change:** `RdYlGN` in `color_continuous_scale=\"RdYlGn\"` to something of your choice\n",
    "  - **Color Reference:** https://plotly.com/python/builtin-colorscales/#builtin-diverging-color-scales\n",
    "- Experiment with different map templates to optimize visuals:\n",
    "  - **Change:** `carto-positron` in `map_style=\"carto-positron\"`\n",
    "  - **Options include:** 'basic', 'carto-darkmatter', 'carto-darkmatter-nolabels', 'carto-positron', 'carto-positron-nolabels', 'carto-voyager', 'carto-voyager-nolabels', 'dark', 'light', 'open-street-map', 'outdoors', 'satellite', 'satellite-streets', 'streets', 'white-bg'\n",
    "\n",
    "**‚ö†Ô∏è Note:** Delete this cell for the final version\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# JMU SENTIMENT ANALYSIS MAP\n",
    "# =============================================================================\n",
    "# Shows the EMOTIONAL tone of how JMU students talk about different places\n",
    "# Red = negative emotions, Green = positive emotions\n",
    "\n",
    "# STEP 1: Calculate average sentiment scores by location\n",
    "# This function groups identical locations and averages their sentiment scores\n",
    "df_jmu_sentiment = create_location_sentiment(\n",
    "    df_jmu,                          # JMU Reddit data with sentiment scores\n",
    "    minimum_count=2,                 # Only places mentioned 2+ times (for reliability)\n",
    "    place_type_filter=None           # Include all place types for comprehensive view\n",
    ")\n",
    "\n",
    "\n",
    "# STEP 2: Create sentiment visualization map\n",
    "# Color represents emotional tone: Green = positive, Red = negative, Yellow = neutral\n",
    "fig_sentiment = px.scatter_map(\n",
    "    df_jmu_sentiment,\n",
    "    lat=\"revised_latitude\",\n",
    "    lon=\"revised_longitude\",\n",
    "    size=\"count\",                    # Larger dots = more mentions (more reliable sentiment)\n",
    "    color=\"avg_sentiment\",           # Color intensity = emotional tone\n",
    "    color_continuous_scale=\"RdYlGn\", # Red-Yellow-Green scale (Red=negative, Green=positive)\n",
    "    hover_name=\"revised_place\",\n",
    "    hover_data={\n",
    "        \"count\": True,               # How many posts contributed to this sentiment\n",
    "        \"avg_sentiment\": \":.3f\",     # Average sentiment score (3 decimal places)\n",
    "        \"place_type\": True,\n",
    "        \"revised_latitude\": \":.4f\",\n",
    "        \"revised_longitude\": \":.4f\",\n",
    "    },\n",
    "    size_max=25,\n",
    "    zoom=2,                          # üìù TO DO: Adjust to focus on interesting patterns\n",
    "    title=\"Average Sentiment by Location in JMU Reddit Posts\",\n",
    "    center=dict(lat=38.5, lon=-86),  # üìù TO DO: Center on region of interest\n",
    ")\n",
    "\n",
    "# STEP 3: Customize layout for sentiment analysis\n",
    "fig_sentiment.update_layout(\n",
    "    map_style=\"carto-positron\",      # Clean background to highlight sentiment colors\n",
    "    width=800, \n",
    "    height=600, \n",
    "    title_font_size=16, \n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "\n",
    "# Display with HTML export configuration\n",
    "fig_sentiment.show(config={'displayModeBar': True, 'displaylogo': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051f112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# YOUR INSTITUTION'S SENTIMENT ANALYSIS MAP\n",
    "# =============================================================================\n",
    "# Compare emotional patterns between your institution and JMU\n",
    "\n",
    "# STEP 1: Calculate sentiment for your institution using identical methods\n",
    "institution_sentiment = create_location_sentiment(\n",
    "    df_institution_cleaned,          # Your cleaned institution data\n",
    "    minimum_count=2,                 # Same minimum as JMU (ensures fair comparison)\n",
    "    place_type_filter=None           # Same filter as JMU (include all place types)\n",
    ")\n",
    "\n",
    "\n",
    "# STEP 2: Create matching sentiment visualization\n",
    "# Use identical settings to JMU map for direct comparison\n",
    "fig_institution_sentiment = px.scatter_map(\n",
    "    institution_sentiment,\n",
    "    lat=\"revised_latitude\",\n",
    "    lon=\"revised_longitude\",\n",
    "    size=\"count\",\n",
    "    color=\"avg_sentiment\",\n",
    "    color_continuous_scale=\"RdYlGn\", # Same color scale as JMU map\n",
    "    hover_name=\"revised_place\",\n",
    "    hover_data={\n",
    "        \"count\": True,\n",
    "        \"avg_sentiment\": \":.3f\",\n",
    "        \"place_type\": True,\n",
    "        \"revised_latitude\": \":.4f\",\n",
    "        \"revised_longitude\": \":.4f\",\n",
    "    },\n",
    "    size_max=25,                     # Same size scale as JMU\n",
    "    zoom=2,                          # üìù TO DO: Adjust for your region\n",
    "    title=\"Average Sentiment by Location in UNC Reddit Posts\",  # üìù TO DO: Update institution name\n",
    "    center=dict(lat=35.5, lon=-80),  # üìù TO DO: Center on your institution's region\n",
    ")\n",
    "\n",
    "# STEP 3: Apply identical layout for comparison\n",
    "fig_institution_sentiment.update_layout(\n",
    "    map_style=\"carto-positron\",      # Same background as JMU map\n",
    "    width=800, \n",
    "    height=600, \n",
    "    title_font_size=16, \n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Display with HTML export configuration\n",
    "fig_institution_sentiment.show(config={'displayModeBar': True, 'displaylogo': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df801ed0",
   "metadata": {},
   "source": [
    "####  Sentiment Comparison Analysis\n",
    "\n",
    "‚úçÔ∏è\n",
    "**Write** \n",
    "You analyzed the place-based sentiments in both corpora. Reflect on how this confirms or complicates your hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4861ab",
   "metadata": {},
   "source": [
    "<div style=\"border-top: 2px solid #64b5f6; margin-top: 30px; padding-top: 20px;\">\n",
    "\n",
    "## Part 6: Time Series Animation Analysis\n",
    "\n",
    "Since the data has a time variable, we can also plot changes in place sentiment over time. This can give insight into whether a particular emotion is consistent or if there was a moment when emotions were better or worse about a location.\n",
    "\n",
    "#### üîß Customization Instructions\n",
    "\n",
    "**Data Filtering:**\n",
    "- Adjust `minimum_count` and `place_type` to render a specific animation of the data you are interested in. (I.e. For \"school spirit\" I am only interested in the University and Buildings with a count over 4)\n",
    "- Adjust `window_months` for smoother transitions between emotions\n",
    "  - This is a rolling average of emotions rather than emotional average per month\n",
    "\n",
    "**Visual Customization:**\n",
    "- Change the center and zoom of the map to properly frame the animation at the right scale and location\n",
    "- Change `color_continuous_scale=\"RdYlGn\"` for best visibility\n",
    "- Experiment with different map templates to optimize visuals:\n",
    "  - **Change:** `carto-positron` in `map_style=\"carto-positron\"`\n",
    "- Experiment with animation duration:\n",
    "  ```python\n",
    "  fig_animated.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 800\n",
    "  fig_animated.layout.updatemenus[0].buttons[0].args[1][\"transition\"][\"duration\"] = 300\n",
    "  ```\n",
    "  - Where 800 and 300 represent milliseconds\n",
    "- Experiment with `size_max` to get the optimal size for the bubbles\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1557ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ANIMATED TIME SERIES: SENTIMENT CHANGES OVER TIME\n",
    "# =============================================================================\n",
    "# Watch how places accumulate mentions and sentiment changes over time\n",
    "# This reveals temporal patterns in student discussions\n",
    "\n",
    "# STEP 1: Prepare animation data with rolling averages\n",
    "# This function creates monthly frames showing cumulative growth and sentiment trends\n",
    "institution_animation = create_time_animation_data(\n",
    "    df_institution_cleaned,          # Your cleaned institution data\n",
    "    window_months=3,                 # 3-month rolling average (smooths out noise)\n",
    "    minimum_count=2,                 # Only places with 2+ total mentions\n",
    "    place_type_filter=None           # Include all place types (üìù TO DO: experiment with filtering)\n",
    ")\n",
    "\n",
    "# STEP 2: Create animated scatter map\n",
    "# Each frame represents one month, showing cumulative mentions and current sentiment\n",
    "fig_animated = px.scatter_map(\n",
    "    institution_animation,\n",
    "    lat=\"revised_latitude\",\n",
    "    lon=\"revised_longitude\",\n",
    "    size=\"cumulative_count\",         # Dot size = total mentions up to this point in time\n",
    "    color=\"rolling_avg_sentiment\",   # Color = 3-month average sentiment (smoother than daily)\n",
    "    animation_frame=\"month\",         # Each frame = one month of data\n",
    "    animation_group=\"revised_place\", # Keep same places connected across frames\n",
    "    hover_name=\"revised_place\",\n",
    "    hover_data={\n",
    "        \"cumulative_count\": True,    # Total mentions so far\n",
    "        \"rolling_avg_sentiment\": \":.3f\", # Smoothed sentiment score\n",
    "        \"place_type\": True,\n",
    "        \"revised_latitude\": \":.4f\",\n",
    "        \"revised_longitude\": \":.4f\"\n",
    "    },\n",
    "    color_continuous_scale=\"RdYlGn\", # Same sentiment colors as static maps\n",
    "    size_max=30,                     # Slightly larger max size for animation visibility\n",
    "    zoom=2,                          # üìù TO DO: Adjust zoom for your region\n",
    "    title=\"Institution Reddit Posts: Cumulative Location Mentions & Rolling Average Sentiment Over Time\",\n",
    "    center=dict(lat=35.5, lon=-80),  # üìù TO DO: Center on your institution's area\n",
    "    range_color=[-0.5, 0.5]          # Fixed color range for consistent comparison across time\n",
    ")\n",
    "\n",
    "# STEP 3: Customize animation settings and layout\n",
    "fig_animated.update_layout(\n",
    "    map_style=\"carto-positron\",\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title_font_size=16,\n",
    "    title_x=0.5,\n",
    "    coloraxis_colorbar=dict(         # Customize the sentiment legend\n",
    "        title=\"Rolling Avg<br>Sentiment\",\n",
    "        tickmode=\"linear\",\n",
    "        tick0=-0.5,                  # Start legend at -0.5 (most negative)\n",
    "        dtick=0.25                   # Tick marks every 0.25 points\n",
    "    )\n",
    ")\n",
    "\n",
    "# STEP 4: Set animation timing (in milliseconds)\n",
    "# üìù TO DO: Experiment with these values for optimal viewing\n",
    "fig_animated.layout.updatemenus[0].buttons[0].args[1][\"frame\"][\"duration\"] = 800    # Time between frames\n",
    "fig_animated.layout.updatemenus[0].buttons[0].args[1][\"transition\"][\"duration\"] = 300 # Transition smoothness\n",
    "\n",
    "# Display with HTML export configuration\n",
    "fig_animated.show(config={'displayModeBar': True, 'displaylogo': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c416ab69",
   "metadata": {},
   "source": [
    "#### ‚úçÔ∏è Time Series Analysis\n",
    "\n",
    "**Write** \n",
    "Explain how you optimized the visuals for your the time series visualization and how this confirms or complicates your hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0455d5bb",
   "metadata": {},
   "source": [
    "<div style=\"border-top: 2px solid #64b5f6; margin-top: 30px; padding-top: 20px;\">\n",
    "\n",
    "## Part 7: Conclusion and Future Research\n",
    "\n",
    "#### ‚úçÔ∏è Final Writing Task\n",
    "\n",
    "**Summarize** all the research you did and establish whether you confirmed your hypothesis. Undoubtedly, your research will fall short. Explain how you would improve the data in the future to better answer your hypothesis.\n",
    "\n",
    "#### üìã Required Elements\n",
    "\n",
    "Your conclusion should address:\n",
    "- **Hypothesis Confirmation:** Did your findings support or contradict your original hypothesis?\n",
    "- **Research Limitations:** What shortcomings did you identify in your analysis?\n",
    "- **Future Improvements:** How would you enhance the data collection or analysis methods?\n",
    "- **Broader Implications:** What do your findings suggest about spatial sentiment analysis?\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
